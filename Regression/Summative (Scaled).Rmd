---
title: "Assignment for ASML (Submodule Regression) Epiphany 2021"
author: "Put your anonymous Z code here"
output:
  pdf_document: default
  html_document: 
    df_print: paged
  html_notebook: 
    df_print: paged
  word_document: default
---


# General Instructions

Please go through the R notebook below, and carry out the requested tasks. You will provide all your answers directly into this .Rmd file. Add code into the R chunks where requested. You can create new chunks where required. Where text answers are requested, please add them directly into this document, typically below the R chunks, using R Markdown syntax as appropriate. 

At the end, you will submit only your `knitted' PDF version of the notebook, through Tunitin on DUO, but not the .Rmd file itself.

**Important notes**: 

* Please ensure carefully that all chunks compile, and also check in the knitted PDF whether all R chunks did *actually* compile, and all images and outputs that you would like to produce have *actually* been generated.  **A picture or a piece of R output which does not exist will give zero marks, even if some parts of the underlying R code would have been correct.**

* Some of the requested analyses requires running R code which is not deterministic. So, you will not have full control over the output that is finally generated in the knitted document. This is fine. It is clear that the methods under investigation carry uncertainty, which is actually part of the problem tackled in this assignment. Your analysis should, however, be robust enough so that it stays in essence correct under repeated execution of your data analysis.  

* We consider a large data set! So, some calculations may take a while, and you will need to be patient. Where code contains loops, it may be a good idea to print the iteration number on the screen so that you know how far the computation has progressed. However, computations should usually not take more than a few minutes, even on an old laptop. So, if a certain computation takes too long, then change your code or methodology, rather than letting your computer struggle for hours!

# Preliminaries

We investigate a dataset introduced in a publication in *Nature* by [Alizadeh (2000)](https://www.researchgate.net/publication/12638392_Distinct_types_of_diffuse_large_B-cell_lymphoma_identified_by_gene_expression_profiling).  This dataset reports gene expression profiles (7399 genes) of 240 patients with B-cell Lymphoma (a tumor that developes from B lymphocytes). The response variable corresponds to patient survival times (in years).  So, this is a truly high-dimensional regression problem, with $p=7399$ predictor variables, but only $n=240$ observations.   

Please use the following steps to read in the data (you may need to install R package `HCmodelSets` first). 

```{r}
require(HCmodelSets)
data(LymphomaData)
?patient.data
```

A few initial steps need to be carried out to prepare the data for analysis. Executing

```{r}
names(patient.data)
dim(patient.data$x)
```

will tell you that the matrix of predictors is given in the wrong orientation for our purposes. So, let's define

```{r}
X <- t(patient.data$x)
colnames(X) <-paste("G", 1:dim(X)[2], sep="")
```

Now, we define the response variable as 

```{r}
Time <- patient.data$time
```


# Task 1: Exploratory data analysis (10 marks)

Using appropriate graphical tools, carry out some exploratory analysis in order to get a better understanding of the data. For instance, it could be useful to provide a histogram of the response, and a scree plot for a principal component analysis of the predictor space. Additional contributions which are more creative than that are welcome. No explanations or comments are required in this task.

**Answer:**

```{r}
# ...

#Exploring the response variable

#Histogram of response
hist(Time) 
#Mean
"Mean Time"
mean(Time)
"STD of Time"
sd(Time)
"sample quantiles of Time"
quantile(Time)
"Number of missing values in Time"
sum(is.na(Time))





#Exploring the Genes (X) variable, Cant explore all as so many so use a random sample of 9 genes
xxx <- 1:7399
ind<-c(sample(xxx,9))
DataExplorer::plot_histogram(X[,ind], ncol = 3)
#Mean
"Mean X"
colMeans(X[,ind])
"STD of X"
sd(X[,ind])
"sample quantiles of X"
quantile(X[,ind])
"Number of missing values in X"
sum(is.na(X[,ind]))


####NEED TO CHECK THIS

##########################
####MAY NEED TO SCLAE DATA
##########################

#(pc.cr <- prcomp(X, cor = TRUE))  # inappropriate
#screeplot(pc.cr)


################################
# Do more 2d plots and box plots
################################




#Exploring the Status variable
"Mean values for X (genes)"
#colMeans(X)
"Counts for the status status"
table(patient.data$status)
```




# Task 2: The Lasso (18 marks)

We would like to reduce the dimension of the currently 7399-dimensional space of predictors. To this end, apply initially the (frequentist) LASSO onto this data set, using the R function `glmnet`. The outputs required are 

* the trace plot of the fitted regression coefficients;
* a graphical illustration of the cross-validation to find $\lambda$.

Provide a short statement interpreting the plots.   

Then, extract and report the value of $\lambda$ which *minimizes* the cross-validation criterion. How many genes are included into the model according to this choice?

**Answer:**

```{r}
Unscale <- function(X,OG) {
  std <- apply(OG, 2, sd)
  meen <- colMeans(OG)
  XX <-sweep(X,2,std,`*`)
  scaled <- sweep(XX, 2, meen, `+`)
  
  return(scaled)
}

Scale <- function(X) {
  std <- apply(X, 2, sd)
  meen <- colMeans(X)
  XX <- sweep(X, 2, meen, `-`)
  X <-sweep(XX,2,std,"/")
  return(X)
}
OG_X<-X

X<-Scale(X)

```

```{r}
# ...

require(glmnet)

gene.lasso<- glmnet(X, Time, family="gaussian", alpha=1)
par(mar = c(6,4,4,2))
plot(gene.lasso, xvar="lambda")
title("trace plot of the fitted regression coefficients", line = +3)

gene.lasso.cv= cv.glmnet(X, Time, alpha=1 )
par(mfrow=c(1,1), mai=c(0.8,0.8,0.8,0.8), cex.axis=2)
plot(gene.lasso.cv)

title("MSE againts log(lambda)", line = +3)

#####################################################
## Provide a short statement interpreting the plots.#
#####################################################


gene.lasso.min_lambda <- gene.lasso.cv$lambda.min
gene.lasso.min_lambda

gene.lasso.coef <- coef(gene.lasso.cv, s="lambda.min")
apply(gene.lasso.coef, 2, function(c)sum(c!=0))

"24 params!"

as.vector(rownames(gene.lasso.coef)[gene.lasso.coef[,1] != 0])

```

# Task 3: Assessing cross-validation resampling uncertainty (20 marks)

We know that the output of the cross-validation routine is not deterministic. To shed further light on this, please carry out a simple experiment. Run the cross-validation and estimation routine for the (frequentist) LASSO 50 times, each time identifying the value of $\lambda$ which minimizes the cross-validation criterion, and each time recording which predictor variables have been selected by the Lasso. When finished, produce a table which lists how often each variable has been included. 

Build a model which includes all variables which have been selected at least 25 (out of 50) times. Refit this model with the selected variables using ordinary least squares. (Benchmark: The value of $R^2$ of this model should not be worse than about 0.45, and your model should not make use of more than ca 25 genes).

Report the names of the selected genes (in terms of the notation defined in the `Preliminaries`) explicitly.

**Answer:**

```{r}
# ...
lambda_vals <- c()

row_names <- c()


require(glmnet)
for(i in 1:50){

  gene.lasso.cv= cv.glmnet(X, Time, alpha=1 )
  
  gene.lasso.min_lambda <- gene.lasso.cv$lambda.min
  lambda_vals[i] <- gene.lasso.min_lambda
  
  gene.lasso.coef <- coef(gene.lasso.cv, s="lambda.min")
  z <- as.vector(rownames(gene.lasso.coef)[gene.lasso.coef[,1] != 0])
  row_names <- c(row_names,z)
  print(i)

}
result<- as.data.frame(table(row_names))
result

data <- result[result[,2] >= 25,] 
data

Selected_var <- as.vector(data[,1])


##Not sure to use lm function or glmnet

########################## check intercepts


b <- paste(Selected_var[-1], collapse="+")
gene.lm.fit <- lm(paste("Time~ ",b,sep = "")	, data = as.data.frame(X))
summary(gene.lm.fit)

"Selected genes:"
Selected_var[-1]
```

# Task 4: Diagnostics (15 marks)

Carry out some residual diagnostics for the model fitted at the end of Task 3, and display the results graphically.

Attempt a Box-Cox transformation, and refit the model using the suggested transformation.  Repeat the residual diagnostics, and also consider the value of $R^2$ of the transformed model. Give your judgement on whether you would prefer the original or the transformed model.

**Answer:**

```{r}
# ...
par(mfrow=c(1,2), cex=0.6)
plot(gene.lm.fit$residuals)
plot(gene.lm.fit$fitted, gene.lm.fit$residuals)

require(MASS)
boxcox(gene.lm.fit)

########################## check intercepts

Trans_fit <- lm(paste("Time^{0}~ ",b,sep = "")	, data = as.data.frame(X))
summary(Trans_fit)


#####################################################
## Provide a short statement ########################
#####################################################
```




# Task 5: Nonparametric smoothing (15 marks)

In this task we are interested in modelling `Time` through a **single** gene, through a nonparametric, univariate, regression model.

Firstly, based on previous analysis, choose a gene which you deem suitable for this task. Provide a scatterplot of the `Time` (vertical) versus  the expression values of that gene (horizontal).

Identify a nonparametric smoother of your choice to carry out this task.  Based on visual inspection, or trial and error, determine a smoothing parameter which appears suitable, and add the resulting fitted curve to the scatterplot.

**Answer:**

```{r}
# ...
require(KernSmooth)

"I will pick one of the genes that has the most counts (i.e 50 counts) in the CV analysis we did above., I chose G4131"

plot(X[,"G4131"], Time)

require(KernSmooth)
h <- dpill(X[,"G4131"], Time, truncate=FALSE)
"h is:"
h

########################## check intercepts


fossil.loc <- locpoly(X[,"G4131"], Time, bandwidth=h)
lines(fossil.loc, col=2)



```




# Task 6: Bootstrap confidence intervals (22 marks)

Continuing from Task 5 (with the same, single, predictor variable, and the same response `Time`), proceed with a more systematic analysis. Specifically, produce a nonparametric smoother featuring

 * a principled way to select the smoothing parameter;
 * bootstrapped confidence bands.

The smoothing method that you use in this Task may be the same or a different one as used in Task 5, but you are *not* allowed to make use of R function `gam`. If you use any built-in R functions to select the smoothing parameter or carry out the bootstrap, explain briefly what they do.

Produce a plot which displays the fitted smoother with the bootstrapped confidence bands. Add to this plot the regression line of a simple linear model with the only predictor variable being the chosen gene (beside the intercept). 

Finally, report the values of $R^2$ of both the nonparametric and the parametric model.  Conclude with a statement on the usefulness of the nonparametric model.

**Answer:**

```{r}
# ...

smooth.loc<- function(x,y,xgrid=x, h){
  N<-length(xgrid)
  smooth.est<-rep(0,N)
  
  for (j in 1:N){
    smooth.est[j]<- lm(y~I(x-xgrid[j]),
    weights=dnorm(x,xgrid[j],h) )$coef[1]
  }
  
  list(x= xgrid, fit=smooth.est)
}

Gene.loc <- smooth.loc(X[,"G4131"], Time, h=h)


Gene.res <- Time - Gene.loc$fit
boot.fit <- matrix(0,200,dim(patient.data$x)[2])

for (j in 1:200){
  boot.res <- sample(Gene.res, size=dim(patient.data$x)[2])
  new.y <- Gene.loc$fit +boot.res
  
  ##### h selection
  h <- dpill(X[,"G4131"], new.y, truncate=FALSE)
  
  boot.fit[j,] <- smooth.loc(X[,"G4131"], new.y, h=h)$fit
}

lower<-upper<- rep(0,dim(patient.data$x)[2])
for (i in 1:dim(patient.data$x)[2]){
  lower[i]<-quantile(boot.fit[,i],0.025)
  upper[i]<-quantile(boot.fit[,i],0.975)
}

plot(X[,"G4131"], Time)
for (j in 1:200){ lines(X[,"G4131"][order(X[,"G4131"])], boot.fit[j,][order(X[,"G4131"])], col="grey")}
lines(X[,"G4131"][order(X[,"G4131"])], Gene.loc$fit[order(X[,"G4131"])])
lines(X[,"G4131"][order(X[,"G4131"])], upper[order(X[,"G4131"])], col=2, lwd=3)
lines(X[,"G4131"][order(X[,"G4131"])], lower[order(X[,"G4131"])], col=2, lwd=3)

tt<-lm(Time ~ X[,"G4131"], data = as.data.frame(X))
summary(tt)$r.squared
abline(tt, col=5, lwd=2)

#############################
######### NEED TO COMPUTE R SQUAREDS
#############################

#####################################################
## Provide a short statement ########################
#####################################################

```

